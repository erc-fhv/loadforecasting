{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import python libraries\n",
    "#\n",
    "import importlib\n",
    "import torch\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.patches import Patch\n",
    "import torch.nn as nn\n",
    "import seaborn as sns\n",
    "import matplotlib.dates as mdates\n",
    "from collections import defaultdict\n",
    "import matplotlib.dates as mdates\n",
    "import matplotlib.gridspec as gridspec\n",
    "\n",
    "# Imports own modules.\n",
    "#\n",
    "from loadforecasting_framework import data_preprocessor, visualization, model_trainer, utils, \\\n",
    "    simulation_config\n",
    "from loadforecasting_framework.simulation_config import *\n",
    "from loadforecasting_models import Normalizer\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate specific model of given power profiles and given configurations\n",
    "#\n",
    "\n",
    "importlib.reload(visualization)\n",
    "importlib.reload(utils)\n",
    "importlib.reload(data_preprocessor)\n",
    "\n",
    "# Define a specific configuration\n",
    "#\n",
    "community_id = 0  # chose one of many energy communites\n",
    "myConfig = \\\n",
    "    ConfigOfOneRun(Model.SIZE_5k, DoTransferLearning.YES, NrOfCommunities.TWENTY, UsedModels.ALL,\n",
    "        AggregationCount.FIFTY_HOUSEHOLDS, DataSplit.TRAIN_12_MONTH, Epochs.DEFAULT)\n",
    "\n",
    "modelTrainer = model_trainer.ModelTrainer()\n",
    "loadProfiles, weatherData, public_holidays_timestamps = modelTrainer.load_data(myConfig)\n",
    "normalizer = Normalizer()\n",
    "my_preprocessor = data_preprocessor.DataPreprocessor(\n",
    "    normalizer = normalizer,\n",
    "    data_split = myConfig.data_split,\n",
    "    add_calendar_year_feature=False,\n",
    "    )\n",
    "X, Y = my_preprocessor.transform_data(\n",
    "    loadProfiles[community_id],\n",
    "    weatherData,\n",
    "    public_holidays_timestamps\n",
    "    )\n",
    "\n",
    "batch, timesteps, features = X['all'].shape\n",
    "\n",
    "# Flatten across batch and timesteps\n",
    "x_flat = X['all'].reshape(batch * timesteps, features)\n",
    "y_flat = Y['all'].reshape(batch * timesteps)\n",
    "\n",
    "feature_names = [\n",
    "    'Monday', 'Tuesday', 'Wednesday', 'Thursday', 'Friday', 'Saturday', 'Sunday',\n",
    "    'Hour-of-day-sine', 'Hour-of-day-cosine', 'Day-of-year-sine', 'Day-of-year-cosine',\n",
    "    'Lagged-power-21d', 'Lagged-power-14d', 'Lagged-power-7d',\n",
    "    'Temperature', 'Dew-point', 'Wind-direction', 'Wind-speed', 'Air-pressure', 'Humidity',\n",
    "]\n",
    "assert features == len(feature_names)\n",
    "\n",
    "# Compute full correlation matrix\n",
    "\n",
    "df = pd.DataFrame(x_flat, columns=feature_names)\n",
    "df['Target'] = y_flat\n",
    "corr = df.corr(numeric_only=True)\n",
    "\n",
    "# Extract just correlations with the target\n",
    "target_corr = corr['Target'].drop('Target')  # drop self-correlation\n",
    "target_corr_df = target_corr.to_frame().rename(columns={'Target': 'correlation'})\n",
    "\n",
    "# Plot as barplot\n",
    "fig_width_inch = 190 / 25.4\n",
    "fig_height_inch = fig_width_inch * 0.6\n",
    "plt.figure(figsize=(fig_width_inch, fig_height_inch))\n",
    "ax=plt.gca()\n",
    "\n",
    "plt.grid(axis='y', linestyle='-', linewidth=0.2, zorder=0)\n",
    "sns.barplot(x=target_corr_df.index, y=target_corr_df.correlation, color='orange', width=0.6, zorder=2) # , color='lightblue'\n",
    "# plt.barh(target_corr_df.index, width=target_corr_df.correlation, height=0.8, color='orange')\n",
    "plt.xticks(rotation=90)\n",
    "plt.ylabel(\"Pearson Correlation Coefficient (-)\")\n",
    "plt.xlabel(\"\")\n",
    "plt.tight_layout()\n",
    "plt.ylim(-1, 1)\n",
    "ax.spines['top'].set_visible(False)\n",
    "ax.spines['right'].set_visible(False)\n",
    "# plt.axhline(y=0,color='gray', linewidth=0.5)\n",
    "plt.savefig(\"outputs/figs/Figure_6.pdf\", format=\"pdf\", bbox_inches=\"tight\")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create Load Profile Plots\n",
    "#\n",
    "\n",
    "importlib.reload(simulation_config)\n",
    "importlib.reload(utils)\n",
    "importlib.reload(model_trainer)\n",
    "\n",
    "########\n",
    "# Setup the test setup configuration\n",
    "#\n",
    "resuts_filename = 'outputs/all_train_histories.pkl'\n",
    "expected_configs = \\\n",
    "    ConfigOfOneRun(Model.SIZE_5k, DoTransferLearning.YES, NrOfCommunities.TWENTY, UsedModels.ALL,\n",
    "        AggregationCount.FIFTY_HOUSEHOLDS, DataSplit.TRAIN_12_MONTH, Epochs.DEFAULT)\n",
    "model_type = 'Transformer'\n",
    "community_id = 0\n",
    "start_date = pd.to_datetime(\"2013-10-01\")\n",
    "end_date = pd.to_datetime(\"2013-12-31\")\n",
    "########\n",
    "\n",
    "# Check, if all data are available\n",
    "# and create a nested dictionary of shape\n",
    "# 'profiles_by_community_size[community_size][model][community_id]'\n",
    "#\n",
    "profiles_by_community_size = utils.Evaluate_Models.get_testrun_results([expected_configs],\n",
    "    resuts_filename)\n",
    "\n",
    "# Calculate the daily nMAE\n",
    "#\n",
    "Y_pred = profiles_by_community_size[expected_configs.aggregation_count[0]][model_type][community_id]\n",
    "Y_real = profiles_by_community_size[expected_configs.aggregation_count[0]]['Perfect'][community_id]\n",
    "Y_pred = torch.tensor(Y_pred.reshape((-1, 24)))\n",
    "Y_real = torch.tensor(Y_real.reshape((-1, 24)))\n",
    "loss_fn = nn.L1Loss(reduction='none')\n",
    "nMAE = (loss_fn(Y_pred, Y_real).mean(dim=1)) / torch.mean(Y_real).item()\n",
    "nMAE *= 100    # Convert to %\n",
    "\n",
    "# Create Plot\n",
    "fig_width_inch = 190 / 25.4\n",
    "fig_height_inch = fig_width_inch * 0.8\n",
    "fig = plt.figure(figsize=(fig_width_inch, fig_height_inch))\n",
    "gs = gridspec.GridSpec(2, 2, height_ratios=[1, 1])\n",
    "\n",
    "# Create Sub-Plot\n",
    "ax1 = plt.subplot(gs[0, :])\n",
    "date_range = pd.date_range(start=start_date, periods=len(nMAE), freq='D')\n",
    "ax1.step(date_range, nMAE, where='post', label='nMAE (%)', color='black')\n",
    "ax1.set_ylabel(f'nMAE (%)', fontsize=10)\n",
    "date_format = mdates.DateFormatter('%b %d')  # Example: Jan 01, 2024\n",
    "ax1.xaxis.set_major_formatter(date_format)\n",
    "tick_positions = np.array([pd.to_datetime(\"2013-10-01\"), pd.to_datetime(\"2013-11-01\"),\n",
    "    pd.to_datetime(\"2013-12-01\"), pd.to_datetime(\"2013-12-31\")])\n",
    "ax1.set_xticks(tick_positions)\n",
    "ax1.set_xlabel(f'Date', fontsize=10)\n",
    "ax1.set_xlim(start_date, end_date)\n",
    "ax1.set_ylim(0, 40)\n",
    "\n",
    "# Find the best and worst days (max and min values in the data)\n",
    "best_day_index = int(np.argmin(nMAE))\n",
    "worst_day_index = int(np.argmax(nMAE))\n",
    "best_day = date_range[best_day_index]\n",
    "worst_day = date_range[worst_day_index]\n",
    "ax1.axvspan(best_day, best_day+pd.Timedelta(days=1), color='lightblue', alpha=0.3,\n",
    "    label=\"Best Forecast\")\n",
    "ax1.axvspan(worst_day, worst_day+pd.Timedelta(days=1), color='orange', alpha=0.3,\n",
    "    label=\"Worst Forecast\")\n",
    "\n",
    "# Add (a) and (b) lables to the figure\n",
    "ax1.text(0.03, 1.1, '(a)', transform=ax1.transAxes, fontsize='medium', va='top', ha='right')\n",
    "\n",
    "\n",
    "########\n",
    "# Setup the test setup configuration\n",
    "#\n",
    "resuts_filename = 'outputs/all_train_histories.pkl'\n",
    "expected_configs = \\\n",
    "    ConfigOfOneRun(Model.SIZE_5k, DoTransferLearning.YES, NrOfCommunities.TWENTY, UsedModels.ALL,\n",
    "        AggregationCount.FIFTY_HOUSEHOLDS, DataSplit.TRAIN_12_MONTH, Epochs.DEFAULT)\n",
    "model_type = 'Transformer'\n",
    "community_id = 0\n",
    "startdate = pd.Timestamp('2013-10-01 00:00:00+00:00')\n",
    "days_to_plot = ['2013-10-04', '2013-12-27']\n",
    "########\n",
    "\n",
    "print(f\"nMAE = {nMAE[best_day_index].item():.1f}% \" \\\n",
    "        f\"of community {community_id} on test day {best_day_index}.\")\n",
    "print(f\"nMAE = {nMAE[worst_day_index].item():.1f}% \" \\\n",
    "        f\"of community {community_id} on test day {worst_day_index}.\")\n",
    "\n",
    "# Check, if all data are available\n",
    "# and create a nested dictionary of shape\n",
    "# 'profiles_by_community_size[community_size][model][community_id]'\n",
    "#\n",
    "profiles_by_community_size = utils.Evaluate_Models.get_testrun_results([expected_configs],\n",
    "    resuts_filename)\n",
    "\n",
    "# Calculate the daily nMAE\n",
    "#\n",
    "Y_pred = profiles_by_community_size[expected_configs.aggregation_count[0]][model_type][community_id]\n",
    "Y_real = profiles_by_community_size[expected_configs.aggregation_count[0]]['Perfect'][community_id]\n",
    "\n",
    "# Create dataframe\n",
    "datetime_index = pd.date_range(start=startdate, periods=Y_real.shape[0], freq='1h')\n",
    "df_Y_plot = pd.DataFrame()\n",
    "df_Y_plot['x'] = datetime_index\n",
    "df_Y_plot['Y_real'] = Y_real / 1000.0\n",
    "df_Y_plot['Y_pred'] = Y_pred / 1000.0\n",
    "fig.canvas.draw()\n",
    "\n",
    "for i, day_to_plot in enumerate(days_to_plot):\n",
    "\n",
    "        ax2 = plt.subplot(gs[1, i])\n",
    "\n",
    "        # Plot only given Day\n",
    "        day_start = pd.to_datetime(day_to_plot).tz_localize('UTC')\n",
    "        day_end = day_start + pd.Timedelta(days=1)\n",
    "        mask = (df_Y_plot['x'] >= day_start) & (df_Y_plot['x'] <= day_end)\n",
    "        df_Y_plot_day = df_Y_plot[mask]\n",
    "\n",
    "        ax2.step(df_Y_plot_day['x'], df_Y_plot_day['Y_pred'], where='post', label='Predicted',\n",
    "            color=['lightblue','orange',][i])\n",
    "        ax2.step(df_Y_plot_day['x'], df_Y_plot_day['Y_real'], where='post', label='Real',\n",
    "            color='black')\n",
    "        ax2.set_ylabel(f'Load (kW)', fontsize=10)\n",
    "        ax2.set_xlabel(f'Time', fontsize=10)\n",
    "        ax2.tick_params(axis='both', which='major', labelsize=8)\n",
    "        ax2.legend(loc='upper left', fontsize=8)\n",
    "        ax2.xaxis.set_major_locator(mdates.HourLocator(interval=3))\n",
    "        ax2.xaxis.set_major_formatter(mdates.DateFormatter('%H:%M'))\n",
    "        ax2.set_xlim(day_start, day_end)\n",
    "        ax2.set_ylim(0, 120)\n",
    "        ax2.tick_params(axis='x', rotation=45)\n",
    "\n",
    "        # Right align the x-axis labels\n",
    "        for tick in ax2.get_xticklabels():\n",
    "                tick.set_horizontalalignment('right')\n",
    "\n",
    "        # Print prediction date\n",
    "        ax2.text(0.99, 0.01, f'Forecast of {pd.to_datetime(day_to_plot).strftime(\"%b %d\")}',\n",
    "                transform=ax2.transAxes,\n",
    "                ha='right', va='bottom',\n",
    "                fontsize=8, color='black')\n",
    "\n",
    "        # Add (b) and (c) lables to the figure\n",
    "        ax2.text(0.06, 1.1, ['(b)','(c)'][i], transform=ax2.transAxes, fontsize='medium',\n",
    "            va='top', ha='right')\n",
    "\n",
    "# Save plot\n",
    "# fig.autofmt_xdate()\n",
    "plt.tight_layout()\n",
    "plt.savefig('outputs/figs/Figure_7.pdf', format='pdf', dpi=300)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compare with and without transfer learning of the given configurations\n",
    "#\n",
    "\n",
    "# Get specific results\n",
    "#\n",
    "importlib.reload(simulation_config)\n",
    "importlib.reload(utils)\n",
    "importlib.reload(model_trainer)\n",
    "\n",
    "########\n",
    "# Setup the test setup configuration\n",
    "#\n",
    "resuts_filename = 'outputs/all_train_histories.pkl'\n",
    "configs = [\n",
    "    ConfigOfOneRun(Model.SIZE_5k, DoTransferLearning.YES, NrOfCommunities.TWENTY, UsedModels.ALL,\n",
    "        AggregationCount.FIFTY_HOUSEHOLDS, DataSplit.TRAIN_2_MONTH, Epochs.DEFAULT),\n",
    "    ConfigOfOneRun(Model.SIZE_5k, DoTransferLearning.YES, NrOfCommunities.TWENTY, UsedModels.ALL,\n",
    "        AggregationCount.FIFTY_HOUSEHOLDS, DataSplit.TRAIN_4_MONTH, Epochs.DEFAULT),\n",
    "    ConfigOfOneRun(Model.SIZE_5k, DoTransferLearning.YES, NrOfCommunities.TWENTY, UsedModels.ALL,\n",
    "        AggregationCount.FIFTY_HOUSEHOLDS, DataSplit.TRAIN_6_MONTH, Epochs.DEFAULT),\n",
    "    ConfigOfOneRun(Model.SIZE_5k, DoTransferLearning.YES, NrOfCommunities.TWENTY, UsedModels.ALL,\n",
    "        AggregationCount.FIFTY_HOUSEHOLDS, DataSplit.TRAIN_9_MONTH, Epochs.DEFAULT),\n",
    "    ConfigOfOneRun(Model.SIZE_5k, DoTransferLearning.YES, NrOfCommunities.TWENTY, UsedModels.ALL,\n",
    "        AggregationCount.FIFTY_HOUSEHOLDS, DataSplit.TRAIN_12_MONTH, Epochs.DEFAULT),\n",
    "    ConfigOfOneRun(Model.SIZE_5k, DoTransferLearning.YES, NrOfCommunities.TWENTY, UsedModels.ALL,\n",
    "        AggregationCount.FIFTY_HOUSEHOLDS, DataSplit.TRAIN_15_MONTH, Epochs.DEFAULT),\n",
    "]\n",
    "\n",
    "machine_learning_model = 'Transformer'\n",
    "basic_model = 'Persistence'\n",
    "training_sizes = ['2', '4', '6', '9', '12', '15']\n",
    "########\n",
    "\n",
    "# Check, if all data are available\n",
    "# and create a nested dictionary of shape 'profiles[community_size][model][community_id]'\n",
    "#\n",
    "profiles = utils.Evaluate_Models.get_testrun_results(configs, resuts_filename,\n",
    "    given_key = 'trainingSize', value_type = 'test_loss_relative')\n",
    "\n",
    "# Create a list of lists, as needed for the violine plot.\n",
    "data_with_ML_model = [profiles[trainingsize][machine_learning_model] for trainingsize in profiles]\n",
    "data_with_basic_model = [profiles[trainingsize][basic_model] for trainingsize in profiles][0]\n",
    "\n",
    "# Creating subplots for violin plots\n",
    "fig_width_inch = 190 / 25.4\n",
    "fig_height_inch = fig_width_inch /2.5\n",
    "fig, ax = plt.subplots(1, 1, figsize=(fig_width_inch, fig_height_inch), sharex=True, sharey=True)\n",
    "\n",
    "# Violin of the machine learning model\n",
    "positions = np.array(range(len(training_sizes))) * 2.0\n",
    "violins_ml_model = ax.violinplot(data_with_ML_model, positions=positions, widths=0.7,\n",
    "                                showmeans=True, showextrema=True, showmedians=False)\n",
    "# Violin of the basic model\n",
    "violins_basic_models = ax.violinplot(data_with_basic_model, positions=[positions[0] + 12],\n",
    "    widths=0.7, showmeans=True, showextrema=True, showmedians=False)\n",
    "\n",
    "# Connect the means\n",
    "data_with_ML_model = np.array(data_with_ML_model)\n",
    "mean_data_with_ML_model = np.mean(data_with_ML_model, axis=1)\n",
    "ax.plot(positions, mean_data_with_ML_model, label=f'{machine_learning_model} Model',\n",
    "            linestyle='--', marker='', color='lightblue')  # training_sizes,\n",
    "\n",
    "# Set custom colors for the violins and vertical lines\n",
    "for pc in violins_ml_model['bodies']:\n",
    "    pc.set_facecolor(\"lightblue\")\n",
    "    pc.set_alpha(0.7)\n",
    "for pc in violins_basic_models['bodies']:\n",
    "    pc.set_facecolor(\"#FFCC80\")\n",
    "    pc.set_alpha(0.7)\n",
    "violins_basic_models['cmeans'].set_color('orange')   # Change the color of the mean lines\n",
    "violins_basic_models['cmins'].set_color('orange')   # Change the color of the minimum lines\n",
    "violins_basic_models['cmaxes'].set_color('orange')  # Change the color of the maximum lines\n",
    "violins_basic_models['cbars'].set_color('orange')  # Change the color of the vertical bars (connectors)\n",
    "\n",
    "# Add horizontal lines for the computed mean\n",
    "mean_basic = np.mean(data_with_basic_model)\n",
    "ax.axhline(mean_basic, color='orange', linestyle='--', linewidth=1, alpha=0.5,\n",
    "    label='Mean of Basic Model')\n",
    "\n",
    "# Labels and title\n",
    "ax.set_ylabel('nMAE (%)')\n",
    "ax.set_ylim(7.5, 25)\n",
    "ax.set_xticks(positions)\n",
    "ax.set_xticklabels(training_sizes)\n",
    "ax.set_axisbelow(True)\n",
    "legend_patches = [\n",
    "    Patch(color=\"lightblue\", label=f\"{machine_learning_model} Model\"),\n",
    "    Patch(color=\"#FFCC80\", label=\"Persistence Prediction\")\n",
    "]\n",
    "ax.legend(handles=legend_patches, loc=\"upper right\")\n",
    "ax.set_xlabel('Training Data Size (Month)')\n",
    "plt.tight_layout()\n",
    "plt.savefig(\"outputs/figs/Figure_8.pdf\", format=\"pdf\", bbox_inches=\"tight\", pad_inches=0.1)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compare with and without transfer learning of the given configurations\n",
    "#\n",
    "\n",
    "importlib.reload(simulation_config)\n",
    "importlib.reload(utils)\n",
    "importlib.reload(model_trainer)\n",
    "\n",
    "########\n",
    "# Setup the test setup configuration\n",
    "#\n",
    "resuts_filename = 'outputs/all_train_histories.pkl'\n",
    "configs = [\n",
    "    # with transfer learning\n",
    "    ConfigOfOneRun(Model.SIZE_5k, DoTransferLearning.YES, NrOfCommunities.TWENTY, UsedModels.ALL,\n",
    "        AggregationCount.FIFTY_HOUSEHOLDS, DataSplit.TRAIN_2_MONTH, Epochs.DEFAULT),\n",
    "    ConfigOfOneRun(Model.SIZE_5k, DoTransferLearning.YES, NrOfCommunities.TWENTY, UsedModels.ALL,\n",
    "        AggregationCount.FIFTY_HOUSEHOLDS, DataSplit.TRAIN_4_MONTH, Epochs.DEFAULT),\n",
    "    ConfigOfOneRun(Model.SIZE_5k, DoTransferLearning.YES, NrOfCommunities.TWENTY, UsedModels.ALL,\n",
    "        AggregationCount.FIFTY_HOUSEHOLDS, DataSplit.TRAIN_6_MONTH, Epochs.DEFAULT),\n",
    "    ConfigOfOneRun(Model.SIZE_5k, DoTransferLearning.YES, NrOfCommunities.TWENTY, UsedModels.ALL,\n",
    "        AggregationCount.FIFTY_HOUSEHOLDS, DataSplit.TRAIN_9_MONTH, Epochs.DEFAULT),\n",
    "    ConfigOfOneRun(Model.SIZE_5k, DoTransferLearning.YES, NrOfCommunities.TWENTY, UsedModels.ALL,\n",
    "        AggregationCount.FIFTY_HOUSEHOLDS, DataSplit.TRAIN_12_MONTH, Epochs.DEFAULT),\n",
    "    ConfigOfOneRun(Model.SIZE_5k, DoTransferLearning.YES, NrOfCommunities.TWENTY, UsedModels.ALL,\n",
    "        AggregationCount.FIFTY_HOUSEHOLDS, DataSplit.TRAIN_15_MONTH, Epochs.DEFAULT),\n",
    "\n",
    "    # without transfer learning\n",
    "    ConfigOfOneRun(Model.SIZE_5k, DoTransferLearning.NO, NrOfCommunities.TWENTY, UsedModels.ALL,\n",
    "        AggregationCount.FIFTY_HOUSEHOLDS, DataSplit.TRAIN_2_MONTH, Epochs.DEFAULT),\n",
    "    ConfigOfOneRun(Model.SIZE_5k, DoTransferLearning.NO, NrOfCommunities.TWENTY, UsedModels.ALL,\n",
    "        AggregationCount.FIFTY_HOUSEHOLDS, DataSplit.TRAIN_4_MONTH, Epochs.DEFAULT),\n",
    "    ConfigOfOneRun(Model.SIZE_5k, DoTransferLearning.NO, NrOfCommunities.TWENTY, UsedModels.ALL,\n",
    "        AggregationCount.FIFTY_HOUSEHOLDS, DataSplit.TRAIN_6_MONTH, Epochs.DEFAULT),\n",
    "    ConfigOfOneRun(Model.SIZE_5k, DoTransferLearning.NO, NrOfCommunities.TWENTY, UsedModels.ALL,\n",
    "        AggregationCount.FIFTY_HOUSEHOLDS, DataSplit.TRAIN_9_MONTH, Epochs.DEFAULT),\n",
    "    ConfigOfOneRun(Model.SIZE_5k, DoTransferLearning.NO, NrOfCommunities.TWENTY, UsedModels.ALL,\n",
    "        AggregationCount.FIFTY_HOUSEHOLDS, DataSplit.TRAIN_12_MONTH, Epochs.DEFAULT),\n",
    "    ConfigOfOneRun(Model.SIZE_5k, DoTransferLearning.NO, NrOfCommunities.TWENTY, UsedModels.ALL,\n",
    "        AggregationCount.FIFTY_HOUSEHOLDS, DataSplit.TRAIN_15_MONTH, Epochs.DEFAULT),\n",
    "]\n",
    "\n",
    "models = ('xLstm', 'Lstm', 'Transformer', )\n",
    "configs_with_transfer = configs[0:6]\n",
    "configs_without_transfer = configs[6:12]\n",
    "training_sizes = ['2', '4', '6', '9', '12', '15']\n",
    "########\n",
    "\n",
    "# Check, if all data are available\n",
    "# and create a nested dictionary of shape 'profiles[trainingSize][model][community_id]'\n",
    "#\n",
    "profiles_w_transfer = utils.Evaluate_Models.get_testrun_results(configs_with_transfer,\n",
    "    resuts_filename, given_key = 'trainingSize', value_type = 'test_loss_relative')\n",
    "profiles_wo_transfer = utils.Evaluate_Models.get_testrun_results(configs_without_transfer,\n",
    "    resuts_filename, given_key = 'trainingSize', value_type = 'test_loss_relative')\n",
    "\n",
    "\n",
    "# Create bar plot with error bars\n",
    "fig_width_inch = 190 / 25.4\n",
    "fig_height_inch = 70 / 25.4\n",
    "fig, ax = plt.subplots(nrows=1, ncols=2, figsize=(fig_width_inch, fig_height_inch), sharey=True)\n",
    "\n",
    "for i, (month, days) in enumerate([('2mo', 61), ('12mo', 365)]):\n",
    "\n",
    "        # Calculate the average improvement with tranfer learning\n",
    "        mean_values_w_transfer, mean_values_wo_transfer = [], []\n",
    "        std_w_transfer, std_wo_transfer = [], []\n",
    "        for model in models:\n",
    "                mean_values_w_transfer.append(np.mean(profiles_w_transfer[days][model]))\n",
    "                mean_values_wo_transfer.append(np.mean(profiles_wo_transfer[days][model]))\n",
    "                std_w_transfer.append(np.std(profiles_w_transfer[days][model]))\n",
    "                std_wo_transfer.append(np.std(profiles_wo_transfer[days][model]))\n",
    "\n",
    "        # Create the barplot\n",
    "        x = np.arange(len(models))\n",
    "        width = 0.3\n",
    "        ax[i].bar(x - width/2, mean_values_wo_transfer, width,\n",
    "        color='orange', edgecolor='black', label=month+' Train Data',\n",
    "        yerr=std_wo_transfer, capsize=3, error_kw=dict(lw=0.8))\n",
    "        ax[i].bar(x + width/2, mean_values_w_transfer, width,\n",
    "        color='lightblue', edgecolor='black', label=month+' Train Data + TL',\n",
    "        yerr=std_w_transfer, capsize=3, error_kw=dict(lw=0.8))\n",
    "\n",
    "        # Axis labels and ticks\n",
    "        ax[i].set_xticks(x)\n",
    "        ax[i].set_xticklabels(models, fontsize=8)\n",
    "        ax[i].tick_params(axis='y', labelsize=8)\n",
    "        ax[i].legend(framealpha=1.0, loc='upper center')\n",
    "\n",
    "        # Add (a) and (b) lables to the figure\n",
    "        ax[i].text(0.06, 1.1, ['(a)','(b)'][i], transform=ax[i].transAxes, fontsize='medium',\n",
    "            va='top', ha='right')\n",
    "\n",
    "# Layout and save\n",
    "ax[0].set_ylabel('nMAE (%)', fontsize=10)\n",
    "ax[0].set_ylim(0, 30)\n",
    "plt.tight_layout()\n",
    "fig.savefig('outputs/figs/Figure_9.pdf', format='pdf', bbox_inches='tight')\n",
    "plt.show()\n",
    "\n",
    "# Print the average improvements of transfer learning\n",
    "mean_values = []\n",
    "for days in [61]:\n",
    "        for model in ['xLstm', 'Lstm', 'Transformer']:\n",
    "            mean_values.append(\n",
    "            np.mean(profiles_wo_transfer[days][model])-np.mean(profiles_w_transfer[days][model]))\n",
    "print(f'Average Improvement due to transfer learning: {np.mean(mean_values):.2f}%.')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compare the effect of the model sizes\n",
    "#\n",
    "\n",
    "# Get specific results\n",
    "#\n",
    "importlib.reload(simulation_config)\n",
    "importlib.reload(utils)\n",
    "importlib.reload(model_trainer)\n",
    "\n",
    "########\n",
    "# Setup the test setup configuration\n",
    "#\n",
    "resuts_filename = 'outputs/all_train_histories.pkl'\n",
    "configs = [\n",
    "    ConfigOfOneRun(Model.SIZE_0k1, DoTransferLearning.YES, NrOfCommunities.TWENTY, UsedModels.ALL,\n",
    "        AggregationCount.FIFTY_HOUSEHOLDS, DataSplit.TRAIN_12_MONTH, Epochs.DEFAULT),\n",
    "    ConfigOfOneRun(Model.SIZE_0k2, DoTransferLearning.YES, NrOfCommunities.TWENTY, UsedModels.ALL,\n",
    "        AggregationCount.FIFTY_HOUSEHOLDS, DataSplit.TRAIN_12_MONTH, Epochs.DEFAULT),\n",
    "    ConfigOfOneRun(Model.SIZE_0k5, DoTransferLearning.YES, NrOfCommunities.TWENTY, UsedModels.ALL,\n",
    "        AggregationCount.FIFTY_HOUSEHOLDS, DataSplit.TRAIN_12_MONTH, Epochs.DEFAULT),\n",
    "    ConfigOfOneRun(Model.SIZE_5k, DoTransferLearning.YES, NrOfCommunities.TWENTY, UsedModels.ALL,\n",
    "        AggregationCount.FIFTY_HOUSEHOLDS, DataSplit.TRAIN_12_MONTH, Epochs.DEFAULT),\n",
    "    ConfigOfOneRun(Model.SIZE_20k, DoTransferLearning.YES, NrOfCommunities.TWENTY, UsedModels.ALL,\n",
    "        AggregationCount.FIFTY_HOUSEHOLDS, DataSplit.TRAIN_12_MONTH, Epochs.DEFAULT),\n",
    "    ConfigOfOneRun(Model.SIZE_40k, DoTransferLearning.YES, NrOfCommunities.TWENTY, UsedModels.ALL,\n",
    "        AggregationCount.FIFTY_HOUSEHOLDS, DataSplit.TRAIN_12_MONTH, Epochs.DEFAULT),\n",
    "    ConfigOfOneRun(Model.SIZE_80k, DoTransferLearning.YES, NrOfCommunities.TWENTY, UsedModels.ALL,\n",
    "        AggregationCount.FIFTY_HOUSEHOLDS, DataSplit.TRAIN_12_MONTH, Epochs.DEFAULT),\n",
    "]\n",
    "model = 'Transformer'\n",
    "########\n",
    "\n",
    "# Check, if all data are available\n",
    "# and create a nested dictionary of shape 'profiles[model_size][model][community_id]'\n",
    "#\n",
    "profiles = utils.Evaluate_Models.get_testrun_results(configs, resuts_filename,\n",
    "    given_key = 'model_size', value_type = 'test_loss_relative')\n",
    "\n",
    "# Calculate the average improvement with tranfer learning\n",
    "#\n",
    "mean_values, std_values = [], []\n",
    "model_sizes = []\n",
    "for model_size in profiles:\n",
    "        values = profiles[model_size][model]\n",
    "        assert len(values) == 20, f'Unexpected nr of communities: {len(values)}'\n",
    "        model_sizes.append(model_size)\n",
    "        mean_values.append(np.mean(values))\n",
    "        std_values.append(np.std(values))\n",
    "\n",
    "# Define figure size\n",
    "fig_width_inch = 90 / 25.4\n",
    "fig_height_inch = fig_width_inch * 0.75 * 2\n",
    "fig, ax = plt.subplots(nrows=2, ncols=1, figsize=(fig_width_inch, fig_height_inch), sharex=True)\n",
    "\n",
    "# Plot with error bars\n",
    "ax[0].plot(mean_values, '--', color='lightblue', linewidth=1.0)\n",
    "ax[0].bar(model_sizes, mean_values, width=0.4,\n",
    "       color='lightblue', edgecolor='black', label='Train with 2mo Data + TL',\n",
    "       yerr=std_values, capsize=2, error_kw=dict(lw=0.8))\n",
    "ax[0].set_ylabel('nMAE (%)', fontsize=10)\n",
    "ax[0].set_ylim(bottom=0, top=30)\n",
    "ax[0].text(0.07, 1.12, '(a)', transform=ax[0].transAxes, fontsize='medium', va='top', ha='right')\n",
    "\n",
    "# Plot training durations\n",
    "durations = [4.71, 4.88, 5.72,  9.15, 11.35, 15.55, 18.68]   # Measured in \"Model_Evaluation.ipynb\"\n",
    "ax[1].plot(durations, '--', color='lightgrey', linewidth=1.0)\n",
    "ax[1].bar(model_sizes, durations, width=0.4,\n",
    "       color='lightgrey', edgecolor='black')\n",
    "ax[1].set_ylabel('Train Duration (min)', fontsize=10)\n",
    "ax[1].set_ylim(bottom=0, top=20)\n",
    "ax[1].text(0.07, 1.12, '(b)', transform=ax[1].transAxes, fontsize='medium', va='top', ha='right')\n",
    "ax[1].set_xlabel('Model Size', fontsize=10)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig('outputs/figs/Figure_10.pdf', format='pdf')\n",
    "plt.show()\n",
    "\n",
    "# Print results\n",
    "print(\"Range of the means: \", np.max(mean_values[1:]) - np.min(mean_values[1:]))\n",
    "print(\"Range of the std-dev: \", np.max(std_values[1:]) - np.min(std_values[1:]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compare forecast error over increasing aggregation level\n",
    "#\n",
    "\n",
    "# Get specific results\n",
    "#\n",
    "importlib.reload(simulation_config)\n",
    "importlib.reload(utils)\n",
    "importlib.reload(model_trainer)\n",
    "\n",
    "########\n",
    "# Setup the test setup configuration\n",
    "#\n",
    "resuts_filename = 'outputs/all_train_histories.pkl'\n",
    "configs = [\n",
    "    ConfigOfOneRun(Model.SIZE_5k, DoTransferLearning.YES, NrOfCommunities.TWENTY, UsedModels.ALL,\n",
    "        AggregationCount.ONE_HOUSEHOLD, DataSplit.TRAIN_12_MONTH, Epochs.DEFAULT),\n",
    "    ConfigOfOneRun(Model.SIZE_5k, DoTransferLearning.YES, NrOfCommunities.TWENTY, UsedModels.ALL,\n",
    "        AggregationCount.TWO_HOUSEHOLDS, DataSplit.TRAIN_12_MONTH, Epochs.DEFAULT),\n",
    "    ConfigOfOneRun(Model.SIZE_5k, DoTransferLearning.YES, NrOfCommunities.TWENTY, UsedModels.ALL,\n",
    "        AggregationCount.TEN_HOUSEHOLDS, DataSplit.TRAIN_12_MONTH, Epochs.DEFAULT),\n",
    "    ConfigOfOneRun(Model.SIZE_5k, DoTransferLearning.YES, NrOfCommunities.TWENTY, UsedModels.ALL,\n",
    "        AggregationCount.FIFTY_HOUSEHOLDS, DataSplit.TRAIN_12_MONTH, Epochs.DEFAULT),\n",
    "    ConfigOfOneRun(Model.SIZE_5k, DoTransferLearning.YES, NrOfCommunities.TWENTY, UsedModels.ALL,\n",
    "        AggregationCount.HUNDRED_HOUSEHOLDS, DataSplit.TRAIN_12_MONTH, Epochs.DEFAULT),\n",
    "    ]\n",
    "model = 'Transformer'\n",
    "household_sizes = ['1', '2', '10', '50', '100']\n",
    "########\n",
    "\n",
    "# Check, if all data are available\n",
    "# and create a nested dictionary of shape 'profiles[community_size][model][community_id]'\n",
    "#\n",
    "profiles = utils.Evaluate_Models.get_testrun_results(configs, resuts_filename,\n",
    "    given_key = 'community_size', value_type = 'test_loss_relative')\n",
    "\n",
    "# Create a list of lists, as needed for the violine plot.\n",
    "data = [profiles[trainingsize][model] for trainingsize in profiles]\n",
    "\n",
    "# Creating subplots for each household size\n",
    "fig, ax = plt.subplots(1, 1, figsize=(7, 3.5), sharex=True, sharey=False)\n",
    "\n",
    "# Plot violin plot\n",
    "positions = np.array(range(len(household_sizes)))\n",
    "violins = ax.violinplot(data, positions=positions, widths=0.28,\n",
    "                        showmeans=True, showextrema=True, showmedians=False)\n",
    "\n",
    "for pc in violins['bodies']:\n",
    "    pc.set_facecolor(\"lightblue\")\n",
    "    # pc.set_edgecolor(\"black\")\n",
    "    pc.set_alpha(0.7)\n",
    "\n",
    "# Connect the means\n",
    "data_with_ML_model = np.array(data)\n",
    "mean_data_with_ML_model = np.mean(data_with_ML_model, axis=1)\n",
    "ax.plot(positions, mean_data_with_ML_model, linestyle='--', marker='', color='lightblue')\n",
    "\n",
    "# Labels and title\n",
    "ax.set_ylabel('nMAE (%)')\n",
    "ax.set_xticks(positions)\n",
    "ax.set_xticklabels(household_sizes)\n",
    "ax.set_axisbelow(True)\n",
    "ax.set_ylim(0, 90)\n",
    "ax.set_xlabel('Community Size (Number of Households)')\n",
    "plt.tight_layout()\n",
    "plt.savefig(\"outputs/figs/Figure_11.pdf\", format=\"pdf\", bbox_inches=\"tight\", pad_inches=0.1)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compare with and without transfer learning of the given configurations\n",
    "#\n",
    "\n",
    "# Get specific results\n",
    "#\n",
    "importlib.reload(simulation_config)\n",
    "importlib.reload(utils)\n",
    "importlib.reload(model_trainer)\n",
    "\n",
    "\n",
    "########\n",
    "# Setup the test setup configuration\n",
    "#\n",
    "resuts_filename = 'outputs/all_train_histories.pkl'\n",
    "configs = [\n",
    "    ConfigOfOneRun(Model.SIZE_5k, DoTransferLearning.YES, NrOfCommunities.TWENTY, UsedModels.ALL,\n",
    "        AggregationCount.ONE_HOUSEHOLD, DataSplit.TRAIN_12_MONTH, Epochs.DEFAULT),\n",
    "    ConfigOfOneRun(Model.SIZE_5k, DoTransferLearning.YES, NrOfCommunities.TWENTY, UsedModels.ALL,\n",
    "        AggregationCount.HUNDRED_HOUSEHOLDS, DataSplit.TRAIN_12_MONTH, Epochs.DEFAULT),\n",
    "    ]\n",
    "models = ('Persistence', 'Knn', 'Lstm', 'xLstm', 'Transformer', )\n",
    "figure_lables = ['1 Household', '2 Households', '10 Households', '50 Households', '100 Households']\n",
    "########\n",
    "\n",
    "# Check, if all data are available\n",
    "# and create a nested dictionary of shape 'profiles[community_size][model][community_id]'\n",
    "#\n",
    "profiles = utils.Evaluate_Models.get_testrun_results(configs, resuts_filename, given_key =\n",
    "    'community_size', value_type = 'test_loss_relative')\n",
    "\n",
    "\n",
    "mean_values, std_values = defaultdict(list), defaultdict(list)\n",
    "for trainingsize in profiles:\n",
    "        for model in models:\n",
    "                values = profiles[trainingsize][model]\n",
    "                assert len(values) == 20, f'Unexpected nr of communities: {len(values)}'\n",
    "                mean_values[trainingsize].append(np.mean(values))\n",
    "                std_values[trainingsize].append(np.std(values))\n",
    "\n",
    "# Plot\n",
    "fig_width_inch = 90 / 25.4\n",
    "fig_height_inch = fig_width_inch * 0.7\n",
    "fig, ax = plt.subplots(1, 1, figsize=(fig_width_inch, fig_height_inch), sharex=True)\n",
    "\n",
    "for idx, trainingsize in enumerate(profiles):\n",
    "    y = np.arange(len(models))\n",
    "    ax.errorbar(\n",
    "        mean_values[trainingsize],\n",
    "        y,\n",
    "        xerr=std_values[trainingsize],\n",
    "        fmt=['o','s'][idx],\n",
    "        ecolor=['black','black'][idx],\n",
    "        elinewidth=0.8,\n",
    "        capsize=7,\n",
    "        color=['lightblue','orange'][idx],\n",
    "        markersize=5,\n",
    "        markeredgecolor=['black','black'][idx],\n",
    "        label=[r'$h=1$','$h=100$', ][idx],\n",
    "        zorder=10\n",
    "    )\n",
    "    ax.plot(mean_values[trainingsize], y, '-', color=['lightblue','orange'][idx], linewidth=0.8,\n",
    "        zorder=0)\n",
    "\n",
    "ax.legend(\n",
    "    loc='upper center',\n",
    "    bbox_to_anchor=(0.44,1.25),\n",
    "    ncol=2,\n",
    "    frameon=False,\n",
    "    fontsize=9,\n",
    "    columnspacing=3,\n",
    "    handletextpad=0.5,\n",
    "    handles=ax.get_legend_handles_labels()[0][::-1],\n",
    "    labels=ax.get_legend_handles_labels()[1][::-1]\n",
    ")\n",
    "\n",
    "ax.set_xlabel('nMAE (%)')\n",
    "ax.set_yticks(range(len(models)))\n",
    "ax.set_yticklabels(models, rotation=0, ha='right')\n",
    "ax.spines['top'].set_visible(False)\n",
    "ax.spines['right'].set_visible(False)\n",
    "ax.grid(axis='x', linestyle='-', linewidth=0.2)\n",
    "ax.set_xlim(0,80)\n",
    "ax.set_xticks(np.arange(0, 81, 10))\n",
    "ax.set_ylim(-0.5,4.5)\n",
    "plt.tight_layout()\n",
    "plt.savefig('outputs/figs/Figure_12.pdf', format='pdf', bbox_inches='tight')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a latex table, containing all informations of the whole experiment\n",
    "#\n",
    "\n",
    "# Get specific results\n",
    "importlib.reload(simulation_config)\n",
    "importlib.reload(utils)\n",
    "importlib.reload(model_trainer)\n",
    "\n",
    "# Get all results\n",
    "# and create a nested dictionary of shape 'result_dict[config][model][community_id]'\n",
    "#\n",
    "result_dict_raw = utils.Evaluate_Models.print_results('outputs/all_train_histories.pkl',\n",
    "    value_type = 'test_loss_relative')\n",
    "\n",
    "# Display only the defined models (i.e. filter out unneeded models)\n",
    "used_models = {'Persistence', 'Knn', 'xLstm', 'Lstm', 'Transformer'}\n",
    "result_dict = defaultdict(dict)\n",
    "for config in result_dict_raw:\n",
    "    for model in result_dict_raw[config]:\n",
    "        if model in used_models:\n",
    "            result_dict[config][model] = result_dict_raw[config][model]\n",
    "\n",
    "# Define the printed configs\n",
    "printed_configs = [\n",
    "\n",
    "    # Vary the model sizes\n",
    "    ConfigOfOneRun(Model.SIZE_0k1, DoTransferLearning.YES, NrOfCommunities.TWENTY, UsedModels.ALL,\n",
    "        AggregationCount.FIFTY_HOUSEHOLDS, DataSplit.TRAIN_12_MONTH, Epochs.DEFAULT),\n",
    "    ConfigOfOneRun(Model.SIZE_0k2, DoTransferLearning.YES, NrOfCommunities.TWENTY, UsedModels.ALL,\n",
    "        AggregationCount.FIFTY_HOUSEHOLDS, DataSplit.TRAIN_12_MONTH, Epochs.DEFAULT),\n",
    "    ConfigOfOneRun(Model.SIZE_0k5, DoTransferLearning.YES, NrOfCommunities.TWENTY, UsedModels.ALL,\n",
    "        AggregationCount.FIFTY_HOUSEHOLDS, DataSplit.TRAIN_12_MONTH, Epochs.DEFAULT),\n",
    "    ConfigOfOneRun(Model.SIZE_5k, DoTransferLearning.YES, NrOfCommunities.TWENTY, UsedModels.ALL,\n",
    "        AggregationCount.FIFTY_HOUSEHOLDS, DataSplit.TRAIN_12_MONTH, Epochs.DEFAULT),\n",
    "   ConfigOfOneRun(Model.SIZE_20k, DoTransferLearning.YES, NrOfCommunities.TWENTY, UsedModels.ALL,\n",
    "        AggregationCount.FIFTY_HOUSEHOLDS, DataSplit.TRAIN_12_MONTH, Epochs.DEFAULT),\n",
    "    ConfigOfOneRun(Model.SIZE_40k, DoTransferLearning.YES, NrOfCommunities.TWENTY, UsedModels.ALL,\n",
    "        AggregationCount.FIFTY_HOUSEHOLDS, DataSplit.TRAIN_12_MONTH, Epochs.DEFAULT),\n",
    "    ConfigOfOneRun(Model.SIZE_80k, DoTransferLearning.YES, NrOfCommunities.TWENTY, UsedModels.ALL,\n",
    "        AggregationCount.FIFTY_HOUSEHOLDS, DataSplit.TRAIN_12_MONTH, Epochs.DEFAULT),\n",
    "\n",
    "   # Vary the tested quarters\n",
    "    ConfigOfOneRun(Model.SIZE_5k, DoTransferLearning.YES, NrOfCommunities.TWENTY, UsedModels.ALL,\n",
    "         AggregationCount.FIFTY_HOUSEHOLDS, DataSplit.TEST_Q1, Epochs.DEFAULT),\n",
    "    ConfigOfOneRun(Model.SIZE_5k, DoTransferLearning.YES, NrOfCommunities.TWENTY, UsedModels.ALL,\n",
    "        AggregationCount.FIFTY_HOUSEHOLDS, DataSplit.TEST_Q2, Epochs.DEFAULT),\n",
    "    ConfigOfOneRun(Model.SIZE_5k, DoTransferLearning.YES, NrOfCommunities.TWENTY, UsedModels.ALL,\n",
    "        AggregationCount.FIFTY_HOUSEHOLDS, DataSplit.TEST_Q3, Epochs.DEFAULT),\n",
    "    ConfigOfOneRun(Model.SIZE_5k, DoTransferLearning.YES, NrOfCommunities.TWENTY, UsedModels.ALL,\n",
    "        AggregationCount.FIFTY_HOUSEHOLDS, DataSplit.TEST_Q4, Epochs.DEFAULT),\n",
    "\n",
    "    # Vary the community sizes\n",
    "    ConfigOfOneRun(Model.SIZE_5k, DoTransferLearning.YES, NrOfCommunities.TWENTY, UsedModels.ALL,\n",
    "        AggregationCount.ONE_HOUSEHOLD, DataSplit.TRAIN_12_MONTH, Epochs.DEFAULT),\n",
    "    ConfigOfOneRun(Model.SIZE_5k, DoTransferLearning.YES, NrOfCommunities.TWENTY, UsedModels.ALL,\n",
    "        AggregationCount.TWO_HOUSEHOLDS, DataSplit.TRAIN_12_MONTH, Epochs.DEFAULT),\n",
    "    ConfigOfOneRun(Model.SIZE_5k, DoTransferLearning.YES, NrOfCommunities.TWENTY, UsedModels.ALL,\n",
    "        AggregationCount.TEN_HOUSEHOLDS, DataSplit.TRAIN_12_MONTH, Epochs.DEFAULT),\n",
    "    ConfigOfOneRun(Model.SIZE_5k, DoTransferLearning.YES, NrOfCommunities.TWENTY, UsedModels.ALL,\n",
    "        AggregationCount.FIFTY_HOUSEHOLDS, DataSplit.TRAIN_12_MONTH, Epochs.DEFAULT),\n",
    "    ConfigOfOneRun(Model.SIZE_5k, DoTransferLearning.YES, NrOfCommunities.TWENTY, UsedModels.ALL,\n",
    "        AggregationCount.HUNDRED_HOUSEHOLDS, DataSplit.TRAIN_12_MONTH, Epochs.DEFAULT),\n",
    "\n",
    "   # Vary the train set size\n",
    "    ConfigOfOneRun(Model.SIZE_5k, DoTransferLearning.YES, NrOfCommunities.TWENTY, UsedModels.ALL,\n",
    "        AggregationCount.FIFTY_HOUSEHOLDS, DataSplit.TRAIN_2_MONTH, Epochs.DEFAULT),\n",
    "    ConfigOfOneRun(Model.SIZE_5k, DoTransferLearning.YES, NrOfCommunities.TWENTY, UsedModels.ALL,\n",
    "        AggregationCount.FIFTY_HOUSEHOLDS, DataSplit.TRAIN_4_MONTH, Epochs.DEFAULT),\n",
    "    ConfigOfOneRun(Model.SIZE_5k, DoTransferLearning.YES, NrOfCommunities.TWENTY, UsedModels.ALL,\n",
    "        AggregationCount.FIFTY_HOUSEHOLDS, DataSplit.TRAIN_6_MONTH, Epochs.DEFAULT),\n",
    "    ConfigOfOneRun(Model.SIZE_5k, DoTransferLearning.YES, NrOfCommunities.TWENTY, UsedModels.ALL,\n",
    "        AggregationCount.FIFTY_HOUSEHOLDS, DataSplit.TRAIN_9_MONTH, Epochs.DEFAULT),\n",
    "    ConfigOfOneRun(Model.SIZE_5k, DoTransferLearning.YES, NrOfCommunities.TWENTY, UsedModels.ALL,\n",
    "        AggregationCount.FIFTY_HOUSEHOLDS, DataSplit.TRAIN_12_MONTH, Epochs.DEFAULT),\n",
    "    ConfigOfOneRun(Model.SIZE_5k, DoTransferLearning.YES, NrOfCommunities.TWENTY, UsedModels.ALL,\n",
    "        AggregationCount.FIFTY_HOUSEHOLDS, DataSplit.TRAIN_15_MONTH, Epochs.DEFAULT),\n",
    "]\n",
    "\n",
    "# Create Table \"with Transfer Learning\"\n",
    "config_names = ['0.1k', '0.2k', '0.5k', '5k', '20k', '40k', '80k',\n",
    "                'Q1', 'Q2', 'Q3', 'Q4',\n",
    "                '1', '2', '10', '50', '100',\n",
    "                '2 mo', '4 mo', '6 mo', '9 mo', '12 mo', '15 mo',\n",
    "                ]\n",
    "config_groups = [{'name':'Model Size', 'rows':7}, '-', '-', '-', '-', '-', '-',\n",
    "                {'name':'Testset<br>(2013)', 'rows':4}, '-', '-', '-',\n",
    "                {'name':'Community<br>Size', 'rows':5}, '-', '-', '-', '-',\n",
    "                {'name':'Training Size', 'rows':6}, '-', '-', '-', '-', '-',\n",
    "                ]\n",
    "configs_with_transfer_learning = printed_configs[:len(config_names)]\n",
    "assert len(config_names) == len(config_groups) == len(configs_with_transfer_learning), \\\n",
    "    f\"Unexpected list length: {len(config_names)} != {len(config_groups)} != \" + \\\n",
    "    f\"{len(configs_with_transfer_learning)}\"\n",
    "utils.Evaluate_Models.print_latex_table(result_dict, configs_with_transfer_learning,\n",
    "    config_groups, config_names)\n",
    "\n",
    "\n",
    "# Without transfer learning:\n",
    "#\n",
    "\n",
    "# Define the printed configs\n",
    "printed_configs = [\n",
    "\n",
    "    # Vary the train set size\n",
    "    ConfigOfOneRun(Model.SIZE_5k, DoTransferLearning.NO, NrOfCommunities.TWENTY, UsedModels.ALL,\n",
    "        AggregationCount.FIFTY_HOUSEHOLDS, DataSplit.TRAIN_2_MONTH, Epochs.DEFAULT),\n",
    "    ConfigOfOneRun(Model.SIZE_5k, DoTransferLearning.NO, NrOfCommunities.TWENTY, UsedModels.ALL,\n",
    "        AggregationCount.FIFTY_HOUSEHOLDS, DataSplit.TRAIN_4_MONTH, Epochs.DEFAULT),\n",
    "    ConfigOfOneRun(Model.SIZE_5k, DoTransferLearning.NO, NrOfCommunities.TWENTY, UsedModels.ALL,\n",
    "        AggregationCount.FIFTY_HOUSEHOLDS, DataSplit.TRAIN_6_MONTH, Epochs.DEFAULT),\n",
    "    ConfigOfOneRun(Model.SIZE_5k, DoTransferLearning.NO, NrOfCommunities.TWENTY, UsedModels.ALL,\n",
    "        AggregationCount.FIFTY_HOUSEHOLDS, DataSplit.TRAIN_9_MONTH, Epochs.DEFAULT),\n",
    "    ConfigOfOneRun(Model.SIZE_5k, DoTransferLearning.NO, NrOfCommunities.TWENTY, UsedModels.ALL,\n",
    "        AggregationCount.FIFTY_HOUSEHOLDS, DataSplit.TRAIN_12_MONTH, Epochs.DEFAULT),\n",
    "    ConfigOfOneRun(Model.SIZE_5k, DoTransferLearning.NO, NrOfCommunities.TWENTY, UsedModels.ALL,\n",
    "        AggregationCount.FIFTY_HOUSEHOLDS, DataSplit.TRAIN_15_MONTH, Epochs.DEFAULT),\n",
    "]\n",
    "\n",
    "# Create Table \"without Transfer Learning\"\n",
    "config_names = [\n",
    "                '2 mo', '4 mo', '6 mo', '9 mo', '12 mo', '15 mo',\n",
    "                ]\n",
    "config_groups = [\n",
    "                {'name':'Training Size', 'rows':6}, '-', '-', '-', '-', '-',\n",
    "                ]\n",
    "assert len(config_names) == len(config_groups) == len(printed_configs), \\\n",
    "    f\"Unexpected list length: {len(config_names)} != {len(config_groups)} != {len(printed_configs)}\"\n",
    "utils.Evaluate_Models.print_latex_table(result_dict, printed_configs, config_groups, config_names)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "load_forecasting",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
