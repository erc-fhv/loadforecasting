{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pickle\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import pandas as pd\n",
    "import importlib\n",
    "from collections import defaultdict\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# All imports are done relative to the \n",
    "# root of the project.\n",
    "#\n",
    "project_root = '../../'\n",
    "if 'change_directory_to_root' not in globals():\n",
    "    change_directory_to_root = True\n",
    "    os.chdir(project_root)\n",
    "\n",
    "# Imports own modules.\n",
    "#\n",
    "import scripts.case_study.OptimizeBESS as OptimizeBESS\n",
    "import scripts.Utils as utils\n",
    "import scripts.Simulation_config as Simulation_config\n",
    "from scripts.Simulation_config import *\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import Price Signal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import energy price in €/Wh\n",
    "#\n",
    "with open('data/exaa_prices_1h.pkl', 'rb') as f:\n",
    "    price_signal = pickle.load(f)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import last Load Forecasts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import electrical load forecast in W\n",
    "#\n",
    "importlib.reload(utils)\n",
    "importlib.reload(Simulation_config)\n",
    "\n",
    "########\n",
    "# Setup the test setup configuration\n",
    "#\n",
    "resuts_filename = 'scripts/outputs/all_train_histories.pkl'\n",
    "expected_configs = [\n",
    "    Config_of_one_run(ModelSize._5k, DoPretraining.YES, DoTransferLearning.YES, Aggregation_Count._1_HOUSEHOLD, NrOfComunities._20, \n",
    "            TrainingHistory._12_MONTH, TestSize._3_MONTH, TrainingFuture._0_MONTH, DevSize._2_MONTH, UsedModels.ALL, Epochs.DEFAULT),\n",
    "    Config_of_one_run(ModelSize._5k, DoPretraining.YES, DoTransferLearning.YES, Aggregation_Count._2_HOUSEHOLDS, NrOfComunities._20, \n",
    "            TrainingHistory._12_MONTH, TestSize._3_MONTH, TrainingFuture._0_MONTH, DevSize._2_MONTH, UsedModels.ALL, Epochs.DEFAULT),\n",
    "    Config_of_one_run(ModelSize._5k, DoPretraining.YES, DoTransferLearning.YES, Aggregation_Count._10_HOUSEHOLDS, NrOfComunities._20, \n",
    "            TrainingHistory._12_MONTH, TestSize._3_MONTH, TrainingFuture._0_MONTH, DevSize._2_MONTH, UsedModels.ALL, Epochs.DEFAULT),\n",
    "    Config_of_one_run(ModelSize._5k, DoPretraining.YES, DoTransferLearning.YES, Aggregation_Count._50_HOUSEHOLDS, NrOfComunities._20, \n",
    "            TrainingHistory._12_MONTH, TestSize._3_MONTH, TrainingFuture._0_MONTH, DevSize._2_MONTH, UsedModels.ALL, Epochs.DEFAULT),\n",
    "    Config_of_one_run(ModelSize._5k, DoPretraining.YES, DoTransferLearning.YES, Aggregation_Count._100_HOUSEHOLDS, NrOfComunities._20, \n",
    "            TrainingHistory._12_MONTH, TestSize._3_MONTH, TrainingFuture._0_MONTH, DevSize._2_MONTH, UsedModels.ALL, Epochs.DEFAULT),\n",
    "    ]\n",
    "########\n",
    "\n",
    "# Get the stored results file from the last test run\n",
    "result_dict = utils.Evaluate_Models.print_results(resuts_filename, print_style = 'predicted_profiles')\n",
    "\n",
    "# Check, if all data are available\n",
    "# and create a nested dictionary of shape 'profiles_by_community_size[community_size][model][community_id]'\n",
    "#\n",
    "profiles_by_community_size = defaultdict(dict)\n",
    "for expected_config in expected_configs:\n",
    "    for available_config in result_dict:\n",
    "        if expected_config == available_config:\n",
    "            community_size = expected_config.aggregation_Count[0]\n",
    "            profiles_by_community_size[community_size] = result_dict[expected_config]\n",
    "assert len(profiles_by_community_size) == len(expected_configs), \\\n",
    "    f\"Not all expected test-runs found: {len(profiles_by_community_size)} != {len(expected_configs)}.\"\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## MILP Optimization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Optimize community size 1 with model \"Perfect\"\n",
      " 0"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19\n",
      "Optimize community size 1 with model \"KNN\"\n",
      " 0 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19\n",
      "Optimize community size 1 with model \"PersistencePrediction\"\n",
      " 0 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19\n",
      "Optimize community size 1 with model \"xLSTM\"\n",
      " 0 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19\n",
      "Optimize community size 1 with model \"LSTM\"\n",
      " 0 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19\n",
      "Optimize community size 1 with model \"Transformer_Encoder_Only\"\n",
      " 0 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19\n",
      "Optimize community size 2 with model \"Perfect\"\n",
      " 0 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19\n",
      "Optimize community size 2 with model \"KNN\"\n",
      " 0 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19\n",
      "Optimize community size 2 with model \"PersistencePrediction\"\n",
      " 0 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19\n",
      "Optimize community size 2 with model \"xLSTM\"\n",
      " 0 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19\n",
      "Optimize community size 2 with model \"LSTM\"\n",
      " 0 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19\n",
      "Optimize community size 2 with model \"Transformer_Encoder_Only\"\n",
      " 0 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19\n",
      "Optimize community size 10 with model \"Perfect\"\n",
      " 0 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19\n",
      "Optimize community size 10 with model \"KNN\"\n",
      " 0 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19\n",
      "Optimize community size 10 with model \"PersistencePrediction\"\n",
      " 0 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19\n",
      "Optimize community size 10 with model \"xLSTM\"\n",
      " 0 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19\n",
      "Optimize community size 10 with model \"LSTM\"\n",
      " 0 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19\n",
      "Optimize community size 10 with model \"Transformer_Encoder_Only\"\n",
      " 0 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19\n",
      "Optimize community size 50 with model \"Perfect\"\n",
      " 0 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19\n",
      "Optimize community size 50 with model \"KNN\"\n",
      " 0 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19\n",
      "Optimize community size 50 with model \"PersistencePrediction\"\n",
      " 0 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19\n",
      "Optimize community size 50 with model \"xLSTM\"\n",
      " 0 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19\n",
      "Optimize community size 50 with model \"LSTM\"\n",
      " 0 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19\n",
      "Optimize community size 50 with model \"Transformer_Encoder_Only\"\n",
      " 0 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19\n",
      "Optimize community size 100 with model \"Perfect\"\n",
      " 0 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19\n",
      "Optimize community size 100 with model \"KNN\"\n",
      " 0 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19\n",
      "Optimize community size 100 with model \"PersistencePrediction\"\n",
      " 0 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19\n",
      "Optimize community size 100 with model \"xLSTM\"\n",
      " 0 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19\n",
      "Optimize community size 100 with model \"LSTM\"\n",
      " 0 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19\n",
      "Optimize community size 100 with model \"Transformer_Encoder_Only\"\n",
      " 0 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19"
     ]
    }
   ],
   "source": [
    "importlib.reload(OptimizeBESS)\n",
    "\n",
    "# Run the MILP optimziation for all communities and model sizes.\n",
    "#\n",
    "costs_per_community_size = defaultdict(lambda: defaultdict(lambda: defaultdict(dict)))\n",
    "\n",
    "for community_size, profiles_per_model in profiles_by_community_size.items():\n",
    "    for model_name, profiles_per_community in profiles_per_model.items():        \n",
    "        \n",
    "        print(f'\\nOptimize community size {community_size} with model \"{model_name}\"')\n",
    "        \n",
    "        if model_name == 'Perfect':\n",
    "            buffer_size = 0.0\n",
    "        else:\n",
    "            buffer_size = 0.1\n",
    "        \n",
    "        for community_id, profile in enumerate(profiles_per_community):\n",
    "            perfect_prediction = profiles_per_model['Perfect'][community_id]\n",
    "            myOptimization = OptimizeBESS.OptimizeBESS( profile, \n",
    "                                                        community_size, \n",
    "                                                        price_signal, \n",
    "                                                        perfect_prediction,\n",
    "                                                        # buffer_size = buffer_size ###################\n",
    "                                                        )\n",
    "            print(f' {community_id}', end='')\n",
    "            optimization_result = myOptimization.run()\n",
    "            costs_per_community_size[community_size][model_name][community_id] = optimization_result\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\\begin{tabular}{lllrll}\n",
      "\\toprule\n",
      "Community Size & Model & nMAE (%) & Costs (€) & Savings (€) & Savings (%) \\\\\n",
      "\\midrule\n",
      "1 Household & Unoptimized &  & 299.06 &  &  \\\\\n",
      " & Perfect & 0.00 & 281.22 & 17.84 & 5.97 \\\\\n",
      " & KNN & 53.84 & 293.58 & 5.48 & 1.83 \\\\\n",
      " & Persistence & 57.25 & 295.44 & 3.62 & 1.21 \\\\\n",
      " & xLSTM & 55.47 & 294.57 & 4.49 & 1.50 \\\\\n",
      " & LSTM & 56.80 & 294.99 & 4.07 & 1.36 \\\\\n",
      " & Transformer & 54.48 & 293.84 & 5.22 & 1.75 \\\\\n",
      "\\midrule\n",
      "2 Households & Unoptimized &  & 495.71 &  &  \\\\\n",
      " & Perfect & 0.00 & 458.31 & 37.41 & 7.55 \\\\\n",
      " & KNN & 39.04 & 476.61 & 19.10 & 3.85 \\\\\n",
      " & Persistence & 44.98 & 479.72 & 15.99 & 3.23 \\\\\n",
      " & xLSTM & 40.23 & 477.84 & 17.87 & 3.61 \\\\\n",
      " & LSTM & 39.77 & 478.54 & 17.18 & 3.47 \\\\\n",
      " & Transformer & 39.93 & 478.30 & 17.41 & 3.51 \\\\\n",
      "\\midrule\n",
      "10 Households & Unoptimized &  & 2218.93 &  &  \\\\\n",
      " & Perfect & 0.00 & 2027.51 & 191.42 & 8.63 \\\\\n",
      " & KNN & 21.63 & 2064.56 & 154.36 & 6.96 \\\\\n",
      " & Persistence & 24.86 & 2078.80 & 140.13 & 6.32 \\\\\n",
      " & xLSTM & 22.11 & 2073.17 & 145.76 & 6.57 \\\\\n",
      " & LSTM & 21.80 & 2072.47 & 146.45 & 6.60 \\\\\n",
      " & Transformer & 21.32 & 2072.75 & 146.17 & 6.59 \\\\\n",
      "\\midrule\n",
      "50 Households & Unoptimized &  & 11601.29 &  &  \\\\\n",
      " & Perfect & 0.00 & 10621.33 & 979.96 & 8.45 \\\\\n",
      " & KNN & 11.24 & 10668.54 & 932.76 & 8.04 \\\\\n",
      " & Persistence & 12.79 & 10693.27 & 908.02 & 7.83 \\\\\n",
      " & xLSTM & 11.05 & 10672.41 & 928.88 & 8.01 \\\\\n",
      " & LSTM & 10.87 & 10672.05 & 929.24 & 8.01 \\\\\n",
      " & Transformer & 10.86 & 10675.13 & 926.17 & 7.98 \\\\\n",
      "\\midrule\n",
      "100 Households & Unoptimized &  & 22590.18 &  &  \\\\\n",
      " & Perfect & 0.00 & 20642.83 & 1947.35 & 8.62 \\\\\n",
      " & KNN & 8.94 & 20697.62 & 1892.55 & 8.38 \\\\\n",
      " & Persistence & 10.10 & 20716.55 & 1873.62 & 8.29 \\\\\n",
      " & xLSTM & 8.55 & 20687.64 & 1902.54 & 8.42 \\\\\n",
      " & LSTM & 8.31 & 20686.81 & 1903.37 & 8.43 \\\\\n",
      " & Transformer & 8.26 & 20689.09 & 1901.08 & 8.42 \\\\\n",
      "\\midrule\n",
      "\\bottomrule\n",
      "\\end{tabular}\n"
     ]
    }
   ],
   "source": [
    "# Calc the normalized mean absolut error:\n",
    "#\n",
    "def calc_nMAE(Y_perfect, Y_model):\n",
    "    loss_fn = nn.L1Loss()\n",
    "    Y_perfect = torch.Tensor(Y_perfect)\n",
    "    Y_model = torch.Tensor(Y_model)\n",
    "    loss = loss_fn(Y_perfect, Y_model)\n",
    "    reference = float(torch.mean(Y_perfect))\n",
    "    nMAE = 100.0 * loss / reference\n",
    "    return float(nMAE)\n",
    "\n",
    "# Print all Results\n",
    "#\n",
    "results = []\n",
    "for nr_of_households, costs_per_model in costs_per_community_size.items():\n",
    "        \n",
    "    # Calculate the average costs without optimization\n",
    "    reference_costs = []\n",
    "    perfect_profiles = profiles_by_community_size[nr_of_households]['Perfect']\n",
    "    for perfect_profile in perfect_profiles:\n",
    "        assert price_signal.shape == perfect_profile.shape, \"Arrays must be the same shape\"\n",
    "        assert price_signal.ndim == 1, \"price_signal must be a 1D array\"\n",
    "        costs = np.sum(price_signal * perfect_profile)\n",
    "        reference_costs.append(costs)\n",
    "    avg_reference_costs = np.mean(reference_costs)\n",
    "    \n",
    "    if nr_of_households == 1:\n",
    "        column_name = f'{nr_of_households} Household'\n",
    "    else:\n",
    "        column_name = f'{nr_of_households} Households'        \n",
    "    \n",
    "    # Store the result\n",
    "    results.append({\n",
    "            \"Community Size\": column_name,\n",
    "            \"Model\": 'Unoptimized',\n",
    "            \"nMAE (%)\": '',\n",
    "            \"Costs (€)\": round(avg_reference_costs, 2),\n",
    "            \"Savings (€)\": '',\n",
    "            \"Savings (%)\": ''\n",
    "        })\n",
    "    \n",
    "    for model_name, costs_per_community in costs_per_model.items():\n",
    "\n",
    "        # Calc the average costs with optimization per model over all communities\n",
    "        all_costs = list(costs_per_community.values())\n",
    "        costs_avg = np.mean(all_costs)\n",
    "        savings_avg = np.mean([(avg_reference_costs - costs) for costs in all_costs])\n",
    "        savings_percent_avg = np.mean([100*(avg_reference_costs - costs)/avg_reference_costs for costs in all_costs])\n",
    "        profile_per_community = profiles_by_community_size[nr_of_households][model_name]\n",
    "        nMAE_avg = np.mean([calc_nMAE(perfect_profiles[i], profile)\n",
    "                            for i, profile in enumerate(profile_per_community)])\n",
    "\n",
    "        # Optionally rename model for printing\n",
    "        if model_name == 'Transformer_Encoder_Only':\n",
    "            model_name = 'Transformer'\n",
    "        elif model_name == 'PersistencePrediction':\n",
    "            model_name = 'Persistence'\n",
    "\n",
    "        results.append({\n",
    "            \"Community Size\": column_name,\n",
    "            \"Model\": model_name,\n",
    "            \"nMAE (%)\": round(nMAE_avg, 2),\n",
    "            \"Costs (€)\": round(costs_avg, 2),\n",
    "            \"Savings (€)\": round(savings_avg, 2),\n",
    "            \"Savings (%)\": round(savings_percent_avg, 2)\n",
    "        })\n",
    "\n",
    "df = pd.DataFrame(results)\n",
    "df[\"Community Size\"] = df[\"Community Size\"].mask(df[\"Community Size\"].duplicated(), \"\")\n",
    "latex = df.to_latex(index=False, float_format=\"%.2f\")\n",
    "\n",
    "# Split into lines\n",
    "lines = latex.splitlines()\n",
    "\n",
    "# Insert horizontal lines ('\\midrule')\n",
    "new_lines = []\n",
    "row_counter = 0\n",
    "for i, line in enumerate(lines):\n",
    "    new_lines.append(line)\n",
    "    if line.endswith(r\"\\\\\") and i > 3 and not line.strip().startswith(r\"\\midrule\"):\n",
    "        row_counter += 1\n",
    "        if row_counter % 7 == 0:\n",
    "            new_lines.append(r\"\\midrule\")\n",
    "latex_modified = \"\\n\".join(new_lines)\n",
    "print(latex_modified)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "load_forecasting2",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
