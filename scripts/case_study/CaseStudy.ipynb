{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pickle\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import pandas as pd\n",
    "import importlib\n",
    "from collections import defaultdict\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# All imports are done relative to the \n",
    "# root of the project.\n",
    "#\n",
    "project_root = '../../'\n",
    "if 'change_directory_to_root' not in globals():\n",
    "    change_directory_to_root = True\n",
    "    os.chdir(project_root)\n",
    "\n",
    "# Imports own modules.\n",
    "#\n",
    "import scripts.case_study.OptimizeBESS as OptimizeBESS\n",
    "import scripts.Utils as utils\n",
    "import scripts.Simulation_config as Simulation_config\n",
    "from scripts.Simulation_config import *\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import Price Signal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import energy price in â‚¬/Wh\n",
    "#\n",
    "with open('data/exaa_prices_1h.pkl', 'rb') as f:\n",
    "    price_signal = pickle.load(f)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import last Load Forecasts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import electrical load forecast in W\n",
    "#\n",
    "importlib.reload(utils)\n",
    "importlib.reload(Simulation_config)\n",
    "\n",
    "########\n",
    "# Setup the test setup configuration\n",
    "#\n",
    "resuts_filename = 'scripts/outputs/all_train_histories.pkl'\n",
    "expected_configs = [\n",
    "    Config_of_one_run(ModelSize._5k, DoPretraining.YES, DoTransferLearning.YES, Aggregation_Count._1_HOUSEHOLD, NrOfComunities._20, \n",
    "            TrainingHistory._12_MONTH, TestSize._3_MONTH, TrainingFuture._0_MONTH, DevSize._2_MONTH, UsedModels.ALL, Epochs.DEFAULT),\n",
    "    Config_of_one_run(ModelSize._5k, DoPretraining.YES, DoTransferLearning.YES, Aggregation_Count._2_HOUSEHOLDS, NrOfComunities._20, \n",
    "            TrainingHistory._12_MONTH, TestSize._3_MONTH, TrainingFuture._0_MONTH, DevSize._2_MONTH, UsedModels.ALL, Epochs.DEFAULT),\n",
    "    Config_of_one_run(ModelSize._5k, DoPretraining.YES, DoTransferLearning.YES, Aggregation_Count._10_HOUSEHOLDS, NrOfComunities._20, \n",
    "            TrainingHistory._12_MONTH, TestSize._3_MONTH, TrainingFuture._0_MONTH, DevSize._2_MONTH, UsedModels.ALL, Epochs.DEFAULT),\n",
    "    Config_of_one_run(ModelSize._5k, DoPretraining.YES, DoTransferLearning.YES, Aggregation_Count._50_HOUSEHOLDS, NrOfComunities._20, \n",
    "            TrainingHistory._12_MONTH, TestSize._3_MONTH, TrainingFuture._0_MONTH, DevSize._2_MONTH, UsedModels.ALL, Epochs.DEFAULT),\n",
    "    Config_of_one_run(ModelSize._5k, DoPretraining.YES, DoTransferLearning.YES, Aggregation_Count._100_HOUSEHOLDS, NrOfComunities._20, \n",
    "            TrainingHistory._12_MONTH, TestSize._3_MONTH, TrainingFuture._0_MONTH, DevSize._2_MONTH, UsedModels.ALL, Epochs.DEFAULT),\n",
    "    ]\n",
    "########\n",
    "\n",
    "# Get the stored results file from the last test run\n",
    "result_dict = utils.Evaluate_Models.print_results(resuts_filename, print_style = 'predicted_profiles')\n",
    "\n",
    "# Check, if all data are available\n",
    "# and create a nested dictionary of shape 'profiles_by_community_size[community_size][model][community_id]'\n",
    "#\n",
    "profiles_by_community_size = defaultdict(dict)\n",
    "for expected_config in expected_configs:\n",
    "    for available_config in result_dict:\n",
    "        if expected_config == available_config:\n",
    "            community_size = expected_config.aggregation_Count[0]\n",
    "            profiles_by_community_size[community_size] = result_dict[expected_config]\n",
    "assert len(profiles_by_community_size) == len(expected_configs), \\\n",
    "    f\"Not all expected test-runs found: {len(profiles_by_community_size)} != {len(expected_configs)}.\"\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## MILP Optimization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Optimize community size 1 with model \"Perfect\"\n",
      " 0 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19\n",
      "Optimize community size 1 with model \"KNN\"\n",
      " 0 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19\n",
      "Optimize community size 1 with model \"PersistencePrediction\"\n",
      " 0 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19\n",
      "Optimize community size 1 with model \"xLSTM\"\n",
      " 0 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19\n",
      "Optimize community size 1 with model \"LSTM\"\n",
      " 0 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19\n",
      "Optimize community size 1 with model \"Transformer_Encoder_Only\"\n",
      " 0 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19\n",
      "Optimize community size 2 with model \"Perfect\"\n",
      " 0 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19\n",
      "Optimize community size 2 with model \"KNN\"\n",
      " 0 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19\n",
      "Optimize community size 2 with model \"PersistencePrediction\"\n",
      " 0 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19\n",
      "Optimize community size 2 with model \"xLSTM\"\n",
      " 0 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19\n",
      "Optimize community size 2 with model \"LSTM\"\n",
      " 0 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19\n",
      "Optimize community size 2 with model \"Transformer_Encoder_Only\"\n",
      " 0 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19\n",
      "Optimize community size 10 with model \"Perfect\"\n",
      " 0 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19\n",
      "Optimize community size 10 with model \"KNN\"\n",
      " 0 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19\n",
      "Optimize community size 10 with model \"PersistencePrediction\"\n",
      " 0 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19\n",
      "Optimize community size 10 with model \"xLSTM\"\n",
      " 0 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19\n",
      "Optimize community size 10 with model \"LSTM\"\n",
      " 0 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19\n",
      "Optimize community size 10 with model \"Transformer_Encoder_Only\"\n",
      " 0 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19\n",
      "Optimize community size 50 with model \"Perfect\"\n",
      " 0 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19\n",
      "Optimize community size 50 with model \"KNN\"\n",
      " 0 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19\n",
      "Optimize community size 50 with model \"PersistencePrediction\"\n",
      " 0 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19\n",
      "Optimize community size 50 with model \"xLSTM\"\n",
      " 0 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19\n",
      "Optimize community size 50 with model \"LSTM\"\n",
      " 0 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19\n",
      "Optimize community size 50 with model \"Transformer_Encoder_Only\"\n",
      " 0 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19\n",
      "Optimize community size 100 with model \"Perfect\"\n",
      " 0 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19\n",
      "Optimize community size 100 with model \"KNN\"\n",
      " 0 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19\n",
      "Optimize community size 100 with model \"PersistencePrediction\"\n",
      " 0 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19\n",
      "Optimize community size 100 with model \"xLSTM\"\n",
      " 0 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19\n",
      "Optimize community size 100 with model \"LSTM\"\n",
      " 0 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19\n",
      "Optimize community size 100 with model \"Transformer_Encoder_Only\"\n",
      " 0 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19"
     ]
    }
   ],
   "source": [
    "importlib.reload(OptimizeBESS)\n",
    "\n",
    "# Run the MILP optimziation for all communities and model sizes.\n",
    "#\n",
    "costs_per_community_size = defaultdict(lambda: defaultdict(lambda: defaultdict(dict)))\n",
    "\n",
    "for community_size, profiles_per_model in profiles_by_community_size.items():\n",
    "    for model_name, profiles_per_community in profiles_per_model.items():        \n",
    "        \n",
    "        print(f'\\nOptimize community size {community_size} with model \"{model_name}\"')\n",
    "        \n",
    "        if model_name == 'Perfect':\n",
    "            buffer_size = 0.0\n",
    "        else:\n",
    "            buffer_size = 0.15\n",
    "        \n",
    "        for community_id, profile in enumerate(profiles_per_community):\n",
    "            perfect_prediction = profiles_per_model['Perfect'][community_id]\n",
    "            myOptimization = OptimizeBESS.OptimizeBESS( profile, \n",
    "                                                        community_size, \n",
    "                                                        price_signal, \n",
    "                                                        perfect_prediction,\n",
    "                                                        buffer_size = buffer_size\n",
    "                                                        )\n",
    "            print(f' {community_id}', end='')\n",
    "            optimization_result = myOptimization.run()\n",
    "            costs_per_community_size[community_size][model_name][community_id] = optimization_result\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calc the normalized mean absolut error:\n",
    "#\n",
    "def calc_nMAE(Y_perfect, Y_model):\n",
    "    loss_fn = nn.L1Loss()\n",
    "    Y_perfect = torch.Tensor(Y_perfect)\n",
    "    Y_model = torch.Tensor(Y_model)\n",
    "    loss = loss_fn(Y_perfect, Y_model)\n",
    "    reference = float(torch.mean(Y_perfect))\n",
    "    nMAE = 100.0 * loss / reference\n",
    "    return float(nMAE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\\begin{tabular}{lllrll}\n",
      "\\toprule\n",
      "Community Size & Model & nMAE (%) & Costs (â‚¬) & Savings (â‚¬) & Savings (%) \\\\\n",
      "\\midrule\n",
      "1 Household & Unoptimized &  & 299.06 &  &  \\\\\n",
      " & Perfect & 0.00 & 280.65 & 18.41 & 6.16 \\\\\n",
      " & KNN & 53.84 & 292.77 & 6.29 & 2.10 \\\\\n",
      " & Persistence & 57.25 & 294.76 & 4.30 & 1.44 \\\\\n",
      " & xLSTM & 49.38 & 290.48 & 8.58 & 2.87 \\\\\n",
      " & LSTM & 49.28 & 290.45 & 8.61 & 2.88 \\\\\n",
      " & Transformer & 50.80 & 290.38 & 8.68 & 2.90 \\\\\n",
      "\\midrule\n",
      "2 Households & Unoptimized &  & 495.71 &  &  \\\\\n",
      " & Perfect & 0.00 & 456.94 & 38.78 & 7.82 \\\\\n",
      " & KNN & 39.04 & 474.73 & 20.98 & 4.23 \\\\\n",
      " & Persistence & 44.98 & 478.09 & 17.62 & 3.55 \\\\\n",
      " & xLSTM & 37.52 & 472.74 & 22.97 & 4.63 \\\\\n",
      " & LSTM & 36.70 & 472.45 & 23.26 & 4.69 \\\\\n",
      " & Transformer & 36.92 & 472.80 & 22.91 & 4.62 \\\\\n",
      "\\midrule\n",
      "10 Households & Unoptimized &  & 2218.93 &  &  \\\\\n",
      " & Perfect & 0.00 & 2019.64 & 199.28 & 8.98 \\\\\n",
      " & KNN & 21.63 & 2058.95 & 159.97 & 7.21 \\\\\n",
      " & Persistence & 24.86 & 2070.55 & 148.38 & 6.69 \\\\\n",
      " & xLSTM & 21.44 & 2060.28 & 158.65 & 7.15 \\\\\n",
      " & LSTM & 20.93 & 2059.24 & 159.69 & 7.20 \\\\\n",
      " & Transformer & 21.15 & 2062.02 & 156.91 & 7.07 \\\\\n",
      "\\midrule\n",
      "50 Households & Unoptimized &  & 11601.29 &  &  \\\\\n",
      " & Perfect & 0.00 & 10581.28 & 1020.01 & 8.79 \\\\\n",
      " & KNN & 11.24 & 10671.82 & 929.48 & 8.01 \\\\\n",
      " & Persistence & 12.79 & 10681.87 & 919.43 & 7.93 \\\\\n",
      " & xLSTM & 11.03 & 10668.87 & 932.42 & 8.04 \\\\\n",
      " & LSTM & 10.86 & 10666.28 & 935.01 & 8.06 \\\\\n",
      " & Transformer & 10.81 & 10665.81 & 935.48 & 8.06 \\\\\n",
      "\\midrule\n",
      "100 Households & Unoptimized &  & 22590.18 &  &  \\\\\n",
      " & Perfect & 0.00 & 20562.84 & 2027.33 & 8.97 \\\\\n",
      " & KNN & 8.94 & 20720.69 & 1869.48 & 8.28 \\\\\n",
      " & Persistence & 10.10 & 20720.22 & 1869.96 & 8.28 \\\\\n",
      " & xLSTM & 8.57 & 20706.99 & 1883.18 & 8.34 \\\\\n",
      " & LSTM & 8.39 & 20699.68 & 1890.50 & 8.37 \\\\\n",
      " & Transformer & 8.33 & 20698.87 & 1891.30 & 8.37 \\\\\n",
      "\\midrule\n",
      "\\bottomrule\n",
      "\\end{tabular}\n"
     ]
    }
   ],
   "source": [
    "# Print all Results in a Latex Table\n",
    "#\n",
    "results = []\n",
    "for nr_of_households, costs_per_model in costs_per_community_size.items():\n",
    "        \n",
    "    # Calculate the average costs without optimization\n",
    "    reference_costs = []\n",
    "    perfect_profiles = profiles_by_community_size[nr_of_households]['Perfect']\n",
    "    for perfect_profile in perfect_profiles:\n",
    "        assert price_signal.shape == perfect_profile.shape, \"Arrays must be the same shape\"\n",
    "        assert price_signal.ndim == 1, \"price_signal must be a 1D array\"\n",
    "        costs = np.sum(price_signal * perfect_profile)\n",
    "        reference_costs.append(costs)\n",
    "    avg_reference_costs = np.mean(reference_costs)\n",
    "    \n",
    "    if nr_of_households == 1:\n",
    "        column_name = f'{nr_of_households} Household'\n",
    "    else:\n",
    "        column_name = f'{nr_of_households} Households'        \n",
    "    \n",
    "    # Store the result\n",
    "    results.append({\n",
    "            \"Community Size\": column_name,\n",
    "            \"Model\": 'Unoptimized',\n",
    "            \"nMAE (%)\": '',\n",
    "            \"Costs (â‚¬)\": round(avg_reference_costs, 2),\n",
    "            \"Savings (â‚¬)\": '',\n",
    "            \"Savings (%)\": ''\n",
    "        })\n",
    "    \n",
    "    for model_name, costs_per_community in costs_per_model.items():\n",
    "\n",
    "        # Calc the average costs with optimization per model over all communities\n",
    "        all_costs = list(costs_per_community.values())\n",
    "        costs_avg = np.mean(all_costs)\n",
    "        savings_avg = np.mean([(avg_reference_costs - costs) for costs in all_costs])\n",
    "        savings_percent_avg = np.mean([100*(avg_reference_costs - costs)/avg_reference_costs for costs in all_costs])\n",
    "        profile_per_community = profiles_by_community_size[nr_of_households][model_name]\n",
    "        nMAE_avg = np.mean([calc_nMAE(perfect_profiles[i], profile)\n",
    "                            for i, profile in enumerate(profile_per_community)])\n",
    "\n",
    "        # Optionally rename model for printing\n",
    "        if model_name == 'Transformer_Encoder_Only':\n",
    "            model_name = 'Transformer'\n",
    "        elif model_name == 'PersistencePrediction':\n",
    "            model_name = 'Persistence'\n",
    "\n",
    "        results.append({\n",
    "            \"Community Size\": column_name,\n",
    "            \"Model\": model_name,\n",
    "            \"nMAE (%)\": round(nMAE_avg, 2),\n",
    "            \"Costs (â‚¬)\": round(costs_avg, 2),\n",
    "            \"Savings (â‚¬)\": round(savings_avg, 2),\n",
    "            \"Savings (%)\": round(savings_percent_avg, 2)\n",
    "        })\n",
    "\n",
    "# Print the dataframe in latex\n",
    "#\n",
    "df = pd.DataFrame(results)\n",
    "df[\"Community Size\"] = df[\"Community Size\"].mask(df[\"Community Size\"].duplicated(), \"\")\n",
    "latex = df.to_latex(index=False, float_format=\"%.2f\")\n",
    "lines = latex.splitlines()\n",
    "new_lines = []\n",
    "row_counter = 0\n",
    "for i, line in enumerate(lines):\n",
    "    new_lines.append(line)\n",
    "    if line.endswith(r\"\\\\\") and i > 3 and not line.strip().startswith(r\"\\midrule\"):\n",
    "        row_counter += 1\n",
    "        if row_counter % 7 == 0:\n",
    "            new_lines.append(r\"\\midrule\")\n",
    "latex_modified = \"\\n\".join(new_lines)\n",
    "print(latex_modified)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "load_forecasting2",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
